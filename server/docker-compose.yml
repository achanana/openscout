# The environment variables such as 
# ${FACE_THRESHOLD} and ${API_KEY} should
# reside in a .env file along side docker-compose.yaml
  
version: '2.3'
services:
  gabriel-server:
    image: cmusatyalab/openscout:${OPENSCOUT_TAG}
    container_name: gabriel-server
    ports:
      - "9099:9099"
      - "5555:5555"
    entrypoint: ["./main.py"]
    restart: unless-stopped
    networks:
      - openscout-net

  http-server:
    image: httpd:2.4
    container_name: http-server
    ports:
      - "${HTTP_PORT}:80"
    restart: unless-stopped
    networks:
      - openscout-net
    volumes:
      - ./openscout-vol:/usr/local/apache2/htdocs

  face-engine:
    image: cmusatyalab/openscout:${OPENSCOUT_TAG}
    container_name: openscout-face-engine
    restart: unless-stopped
    privileged: true
    entrypoint: ["./face.py", "--endpoint", "http://openface-service:5000", "--threshold", "${FACE_THRESHOLD}", "${STORE}"]
    #to use MS Face Cognitive Service, make this the entrypoint instead and use the ms-face-server container...
    #entrypoint: ["./face.py", "--msface", "--endpoint", "http://ms-face-service:5000","--apikey", "${API_KEY}", "--threshold", "${FACE_THRESHOLD}"]
    volumes:
      - ./openscout-vol:/openscout/server/images/
      - training-vol:/openscout/server/training/
    depends_on:
      - gabriel-server
      - openface-service
      #- ms-face-service
    networks:
      - openscout-net
      - elk
    environment:
      - WEBSERVER=${WEBSERVER_URL}:${HTTP_PORT}

  object-engine:
    image: cmusatyalab/openscout:${OPENSCOUT_TAG}
    container_name: openscout-object-engine
    restart: unless-stopped
    privileged: true
    entrypoint: ["./obj.py", "--model", "${DNN}", "--threshold", "${OBJ_THRESHOLD}", "--exclude", "${EXCLUSIONS}", "${STORE}"]
    # for NVIDIA GPUs
    # gpus: all     # not yet supported by docker-compose
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ./openscout-vol:/openscout/server/images/
    depends_on:
      - gabriel-server
    networks:
      - openscout-net
      - elk
    environment:
       - WEBSERVER=${WEBSERVER_URL}:${HTTP_PORT}
    #  - TF_FORCE_GPU_ALLOW_GROWTH=true #the following environment variable may be necessary if your GPU only has a modest (~2GB) amount of RAM
    #  - CUDA_VISIBLE_DEVICES=-1 #set this if you want to force CPU only

  obstacle-engine:
    image: cmusatyalab/openscout:${OPENSCOUT_TAG}
    container_name: obstacle-engine
    restart: unless-stopped
    privileged: true
    entrypoint: ["./depth.py", "--model", "${MIDAS}", "--threshold", "${DEPTH_THRESHOLD}", "${STORE}"]
    # for NVIDIA GPUs
    # gpus: all     # not yet supported by docker-compose
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ./openscout-vol:/openscout/server/images/
    depends_on:
      - gabriel-server
    networks:
      - openscout-net
      - elk
    #environment:
    #  - TF_FORCE_GPU_ALLOW_GROWTH=true #the following environment variable may be necessary if your GPU only has a modest (~2GB) amount of RAM
    #  - CUDA_VISIBLE_DEVICES=-1 #set this if you want to force CPU only

# OpenFace is the default for face recognition
  openface-service:
    image: cmusatyalab/openface
    container_name: openface-service
    ports:
      - "5000:5000"
    restart: unless-stopped
    privileged: true
    entrypoint: ["python", "/root/openface-rest.py", "/openscout/server/training/"]
    volumes:
      - training-vol:/openscout/server/training/
    networks:
      - openscout-net

# or the MS Face Cognitive Server can be used (Azure Account Required)
  # ms-face-service:
  #   image: containerpreview.azurecr.io/microsoft/cognitive-services-face
  #   container_name: ms-face-service
  #   restart: unless-stopped
  #   ports:
  #     - "5000:5000"
  #   networks:
  #     - openscout-net
  #   cpus: '1.0'
  #   mem_reservation: 4gb
  #   environment:
  #     - Eula=accept
  #     - Billing=${BILLING_ENDPOINT}
  #     - ApiKey=${API_KEY}
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch-oss:${ELK_VERSION}-amd64
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
    ports:
      - 9200:9200
    restart: unless-stopped
    privileged: true
    networks:
      - elk
  kibana:
    image: docker.elastic.co/kibana/kibana-oss:${ELK_VERSION}
    container_name: kibana
    ports:
      - 5601:5601
    restart: unless-stopped
    privileged: true
    networks:
      - elk
    depends_on:
      - elasticsearch
  logstash:
    image: docker.elastic.co/logstash/logstash-oss:${ELK_VERSION}
    container_name: logstash
    ports:
      - 5044:5044
    restart: unless-stopped
    privileged: true
    networks:
      - elk
    volumes:
      - ./elk/pipeline/:/usr/share/logstash/pipeline/
    depends_on:
      - elasticsearch
networks:
  openscout-net:
  elk:
volumes:
  training-vol:

